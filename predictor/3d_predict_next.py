# predictor/predict_next.py

import pandas as pd
import numpy as np
import sys
import os
import joblib
from collections import Counter
from lightgbm import LGBMClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.multiclass import OneVsRestClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from sklearn.ensemble import VotingClassifier
from dotenv import load_dotenv
load_dotenv()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°æ¨¡å—æœç´¢è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
LABELS_PATH = os.path.join(BASE_DIR, "data", "3d_shijihao_labels.csv")
MODEL_DIR = os.path.join(BASE_DIR, "models", "cached")
os.makedirs(MODEL_DIR, exist_ok=True)

FEATURE_COLUMNS = [
    'sim_sum_val', 'sim_span',
    'open_digit_1', 'open_digit_2', 'open_digit_3',
    'open_sum_val', 'open_span',
    'match_count', 'match_pos_count',
    'sim_pattern_ç»„ä¸‰', 'sim_pattern_ç»„å…­', 'sim_pattern_è±¹å­',
    'open_pattern_ç»„ä¸‰', 'open_pattern_ç»„å…­', 'open_pattern_è±¹å­'
]

PATTERN_MAP = {"ç»„å…­": 0, "ç»„ä¸‰": 1, "è±¹å­": 2}
REVERSE_PATTERN_MAP = {v: k for k, v in PATTERN_MAP.items()}

print("\U0001F4E5 åŠ è½½æ•°æ®...")
df = pd.read_csv(LABELS_PATH).dropna().reset_index(drop=True)
# === æ–°å¢žï¼š rolling çƒ­åº¦ç‰¹å¾ ===
df['single_hot_5'] = df['single_digit'].rolling(5, min_periods=1).apply(lambda x: Counter(x).most_common(1)[0][1])
df['single_hot_3'] = df['single_digit'].rolling(3, min_periods=1).apply(lambda x: Counter(x).most_common(1)[0][1])
FEATURE_COLUMNS += ['single_hot_5', 'single_hot_3']
for col in [
    'sim_pattern_ç»„ä¸‰', 'sim_pattern_ç»„å…­', 'sim_pattern_è±¹å­',
    'open_pattern_ç»„ä¸‰', 'open_pattern_ç»„å…­', 'open_pattern_è±¹å­'
]:
    if col not in df.columns:
        df[col] = 0

total_samples = len(df)
window_size = 700
idx = total_samples - 1
train_df = df.iloc[idx - window_size:idx].copy()
eval_df = df.iloc[[idx]].copy()

X_train = train_df[FEATURE_COLUMNS]
X_eval = eval_df[FEATURE_COLUMNS]

path_digit = os.path.join(MODEL_DIR, "3d_model_digit.pkl")
path_single = os.path.join(MODEL_DIR, "3d_model_single.pkl")
path_kill1 = os.path.join(MODEL_DIR, "3d_model_kill1.pkl")
path_pattern = os.path.join(MODEL_DIR, "3d_model_pattern.pkl")
path_group7 = os.path.join(MODEL_DIR, "3d_model_group7.pkl")

if os.path.exists(path_digit):
    model_digit = joblib.load(path_digit)
else:
    model_digit = MultiOutputClassifier(
        VotingClassifier(estimators=[
            ('lgb', LGBMClassifier(verbosity=-1)),
            ('xgb', XGBClassifier(verbosity=0)),
            ('cat', CatBoostClassifier(verbose=0))
        ], voting='soft')
    ).fit(X_train, train_df[['sim_digit_1', 'sim_digit_2', 'sim_digit_3']])
    joblib.dump(model_digit, path_digit)

pred_digits = list(map(int, model_digit.predict(X_eval)[0]))

last_issue = str(eval_df['issue'].values[0])
if last_issue.isdigit() and len(last_issue) == 7:
    prefix = last_issue[:4]
    suffix = int(last_issue[4:]) + 1
    if suffix > 999:
        suffix = 1
        prefix = str(int(prefix) + 1)
    next_issue = f"{prefix}{suffix:03d}"
else:
    next_issue = last_issue + "_next"

print(f"âœ¨ ä¸‹ä¸€æœŸ({next_issue}) é¢„æµ‹è¯•æœºå·: {''.join(map(str, pred_digits))}")

from sklearn.multiclass import OneVsRestClassifier

# === æ–°å¤šæ ‡ç­¾ç‹¬èƒ† One-vs-Rest è®­ç»ƒ ===
# åˆ›å»º 10 ä¸ªäºŒåˆ†ç±»æ ‡ç­¾ï¼Œæ˜¯å¦å‡ºçŽ° 0~9
for d in range(10):
    train_df[f'single_{d}'] = (train_df['single_digit'] == d).astype(int)

target_cols = [f'single_{d}' for d in range(10)]

path_single_multi = os.path.join(MODEL_DIR, "3d_model_single_multi.pkl")

if os.path.exists(path_single_multi):
    model_single_multi = joblib.load(path_single_multi)
else:
    model_single_multi = OneVsRestClassifier(
        LGBMClassifier(verbosity=-1, class_weight='balanced')
    )

    model_single_multi.fit(X_train, train_df[target_cols])
    joblib.dump(model_single_multi, path_single_multi)

# é¢„æµ‹æ—¶è¾“å‡º 10 ç»´æ¦‚çŽ‡ï¼Œé€‰æ¦‚çŽ‡æœ€å¤§è€…
proba_single = model_single_multi.predict_proba(X_eval)[0]
pred_single = int(np.argmax(proba_single))
print(f"ðŸ”¸ ç‹¬èƒ†(å¤šæ ‡ç­¾): {pred_single} | æ¦‚çŽ‡åˆ†å¸ƒ: {np.round(proba_single, 3)}")


try:
    kill_candidates = []
    all_probas = []

    for i, target_col in enumerate(['sim_digit_1', 'sim_digit_2', 'sim_digit_3']):
        model_path = os.path.join(MODEL_DIR, f"3d_model_sim_digit_{i+1}.pkl")
        if os.path.exists(model_path):
            model = joblib.load(model_path)
        else:
            model = LGBMClassifier(verbosity=-1).fit(X_train, train_df[target_col])
            joblib.dump(model, model_path)

        proba = model.predict_proba(X_eval)[0]
        proba = proba / np.sum(proba)  # âœ… æ¦‚çŽ‡å½’ä¸€åŒ–
        all_probas.append(proba)

        lowest = np.argsort(proba)[:2]  # æ¯ä¸ªä½æœ€ä½Žä¸¤ä¸ª
        kill_candidates.extend(lowest)

    # å‡ºçŽ°æ¬¡æ•°ç»Ÿè®¡
    count = Counter(kill_candidates)
    # å‡ºçŽ°æ¬¡æ•°ä»Žå¤šåˆ°å°‘æŽ’åºï¼Œé€‰å‡ºçŽ° >= 2 æ¬¡çš„
    kill_two = [num for num, c in count.most_common() if c >= 3][:2]

    if len(kill_two) < 1:
        sum_proba = np.sum(all_probas, axis=0)
        backup = sorted(np.argsort(sum_proba)[:2])
        for b in backup:
            if b not in kill_two and len(kill_two) < 1:
                kill_two.append(b)

    # === æ–°å¢žï¼šå‡ºçŽ°é¢‘æ¬¡è¿‡æ»¤ï¼ˆè¿‘3æœŸï¼‰
    recent_open = ''.join(df['open_code'].astype(str).tolist()[-3:])
    kill_two = [k for k in kill_two if str(k) not in recent_open]

    kill_two = sorted(kill_two)
    print(f"âŒ æ€äºŒ: {kill_two} (ä¿å®ˆ+è¿‡æ»¤)")

except Exception as e:
    print("âš ï¸ æ€äºŒèžåˆé¢„æµ‹å¤±è´¥:", str(e))


try:
    from xgboost import XGBClassifier
    from catboost import CatBoostClassifier
    from sklearn.ensemble import VotingClassifier

    train_df['pattern_label'] = train_df['sim_pattern'].map(PATTERN_MAP)
    path_pattern = os.path.join(MODEL_DIR, "3d_model_pattern_vote.pkl")
    if os.path.exists(path_pattern):
        model_pattern = joblib.load(path_pattern)
    else:
        model_pattern = VotingClassifier(estimators=[
            ('lgb', LGBMClassifier(verbosity=-1)),
            ('xgb', XGBClassifier(verbosity=0)),
            ('cat', CatBoostClassifier(verbose=0))
        ], voting='soft')
        model_pattern.fit(X_train, train_df['pattern_label'])
        joblib.dump(model_pattern, path_pattern)
    pred_label = int(model_pattern.predict(X_eval)[0])
    pattern_name = REVERSE_PATTERN_MAP.get(pred_label, "æœªçŸ¥")
    print(f"ðŸ”€ å½¢æ€: {pattern_name}")
except Exception as e:
    print("âš ï¸ å½¢æ€é¢„æµ‹å¤±è´¥:", str(e))


try:
    group_cols = [f'group7_digit_{i}' for i in range(1, 8)]
    if os.path.exists(path_group7):
        model_group7 = joblib.load(path_group7)
    else:
        model_group7 = MultiOutputClassifier(LGBMClassifier(verbosity=-1)).fit(X_train, train_df[group_cols])
        joblib.dump(model_group7, path_group7)
    pred_group = sorted(set(map(int, model_group7.predict(X_eval)[0])))
    print(f"âœ¨ ä¸ƒç ç»„é€‰: {pred_group}")
    print(f"âœ¨å…­ç ç»„é€‰: {pred_group[:6]}")
    print(f"âœ¨äº”ç ç»„é€‰: {pred_group[:5]}")
except Exception as e:
    print("âš ï¸ ç»„é€‰é¢„æµ‹å¤±è´¥:", str(e))

# æ–°æ–¹æ¡ˆï¼šä½¿ç”¨ sim_digit_1/2/3 åˆ†åˆ«é¢„æµ‹ ç™¾åä¸ªä½ Top3
for pos, name, target_col in zip(['bai', 'shi', 'ge'], ['ç™¾', 'å', 'ä¸ª'], ['sim_digit_1', 'sim_digit_2', 'sim_digit_3']):
    try:
        model_path = os.path.join(MODEL_DIR, f"3d_model_ding3_{pos}.pkl")
        if os.path.exists(model_path):
            model = joblib.load(model_path)
        else:
            model = LGBMClassifier(verbosity=-1).fit(X_train, train_df[target_col])
            joblib.dump(model, model_path)
        proba = model.predict_proba(X_eval)[0]
        top3 = [int(x) for x in np.argsort(proba)[-3:][::-1]]
        print(f"ðŸ“ {name}ä½å®š3: {top3}")
        print(f"ðŸ“ {name}ä½å®š1: [{top3[0]}]")
    except Exception as e:
        print(f"âš ï¸ {pos}ä½æ¦‚çŽ‡é¢„æµ‹å¤±è´¥: {str(e)}")



# ========== âœ… å¾®ä¿¡æé†’é›†æˆï¼ˆä¼˜åŒ–ä¸ºé€ä¸ªå‘é€ï¼‰ ==========
try:
    import time
    from notifier.wechat_notify import send_wechat_template

    # ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–æŽ¥æ”¶äºº
    to_users_env = os.getenv("WECHAT_TO_USERS", "")
    to_users = [uid.strip() for uid in to_users_env.split(",") if uid.strip()]
    if not to_users:
        raise ValueError("âŒ å¾®ä¿¡æé†’å‘é€å¤±è´¥ï¼šçŽ¯å¢ƒå˜é‡ WECHAT_TO_USERS æœªè®¾ç½®æˆ–ä¸ºç©º")


    # âš¡ æ‹¼è£…å››æ®µå†…å®¹ï¼ˆæ–°ç‰ˆç»“æž„ï¼‰
    title = f"ç¦å½©3D-{next_issue}æœŸ-æ‹¼æè¯•æœºé¢„æµ‹"
    content1 = f"é¢„æµ‹å·: {''.join(map(str, pred_digits))}|ç‹¬èƒ†:{pred_single}|å½¢æ€:{pattern_name}"
    content2 = f"æ€äºŒ:{' '.join(map(str, kill_two))}|ä¸ƒç :{''.join(map(str, pred_group))}"
    content3 = f"å…­ç :{''.join(map(str, pred_group[:6]))}|äº”ç :{''.join(map(str, pred_group[:5]))}"
    remark = "ðŸ” æ›´å¤šè¯¦æƒ…è¯·æŸ¥çœ‹æ—¥å¿—è¾“å‡ºæˆ–ç½‘é¡µæŽ¨é€"

    # âœ… æŽ§åˆ¶å°æ‰“å°
    print("\n====== ðŸ“£ å³å°†å‘é€çš„å¾®ä¿¡æ¶ˆæ¯å†…å®¹ï¼ˆæ–°ç‰ˆï¼‰ ======")
    print(f"ðŸŽ¯ æ ‡é¢˜: {title}")
    print(f"âœ… å†…å®¹1: {content1}")
    print(f"âœ… å†…å®¹2: {content2}")
    print(f"âœ… å†…å®¹3: {content3}")
    print(f"âœ… å¤‡æ³¨: {remark}")
    print("=============================================\n")

    for user in to_users:
        send_wechat_template([user], title, content1, content2, content3, remark)
        time.sleep(3)  # æ ¹æ®éœ€è¦å¯è°ƒæ•´

except Exception as e:
    print(f"âš ï¸ å¾®ä¿¡æé†’å‘é€å¤±è´¥: {e}")

# ========== âœ… å°†é¢„æµ‹ç»“æžœä¿å­˜åˆ° CSV ==========
import csv

# ä¿å­˜è·¯å¾„ï¼šé¡¹ç›®æ ¹ç›®å½• / data / predict_result.csv
save_path = os.path.join(BASE_DIR, "data", "predict_result.csv")

# æž„é€ ä¸€æ¡è®°å½•
record = {
    "issue": next_issue,
    "pred_digits": ''.join(map(str, pred_digits)),
    "pred_single": pred_single,
    "pattern": pattern_name,
    "kill_two": ','.join(map(str, kill_two)),
    "group7": ','.join(map(str, pred_group)),
    "group6": ','.join(map(str, pred_group[:6])),
    "group5": ','.join(map(str, pred_group[:5])),
}

# å¦‚æžœæ–‡ä»¶ä¸å­˜åœ¨åˆ™å†™æ ‡é¢˜
write_header = not os.path.exists(save_path)

with open(save_path, mode='a', newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=record.keys())
    if write_header:
        writer.writeheader()
    writer.writerow(record)

print(f"âœ… å·²ä¿å­˜é¢„æµ‹ç»“æžœåˆ° {save_path}")
